<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Motor de busca textual com R, Shiny e PostgreSQL</title>
    <meta charset="utf-8" />
    <meta name="author" content="José de Jesus Filho" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Motor de busca textual com R, Shiny e PostgreSQL
### José de Jesus Filho
### Consudata consultoria em organização e análise de dados jurídicos
### São Paulo, 06 de Dezembro de 2019

---




# Introdução

A apresentação mostrará como estruturar uma base de dados de textos no PostgreSQL, tokenizá-los e montar um índice invertido a fim de realizar buscas textuais em grande volumes de documentos em poucos segundos. Os textos serão organizados a partir do R, enviados para o PostgreSQL, indexados e de lá chamados a partir de um aplicativo shiny.
---

# Prerrequisitos

Supondo um ambiente de desenvolvimento, considero aqui a instalação do PostgreSQL, do RStudio e do Shiny numa única máquina. Em produção, eu crio uma rede privada de máquinas virtuais e distribuo as funcionalidades.

```r
- PostgreSQL instalado (irei mostrar como instalar no Ubuntu);
- R, RStudio e Shiny instalados;
- Pacotes DBI, RPostgres, dbx, pool, glue,abjutils e D instalados;
- Tidyverse 

```
---

# Porque usar o PostgreSQL

- Fácil de instalar;
- Bem documentado;
- Ampla comunidade;
- Software livre;
- Funciona como motor de busca textual, dispensando o uso do
Solr ou do Elasticsearch;

# Instalar o PostgreSQL

Para manter a versão mais recente do Postgres, seguir o seguinte procedimento: 

## Adicionar a chave GPG
```sh
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
```
Em seguida, adicione o repositório com o comando abaixo:
```sh
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main" &gt;&gt; /etc/apt/sources.list.d/pgdg.list'

```
Feito isso, o passo seguinte é instalar o PostgreSQL:

```sh
sudo apt update
sudo apt install postgresql postgresql-contrib
```
---
# Configuração do locale
O PostgreSQL adota o locale da sua máquina, então é importante assegurar que o locale está configurado para `pt_BR.UTF-8`. Crie um arquivo e adicione o script para configuração do locale:
```sh
sudo touch set_locale.sh ## criação do arquivo
```
Script:
```r
#!/bin/bash
# Set locales in /etc/default/locale file
echo "Setting locale..."
echo "# Locale settings
export LANGUAGE=pt_BR.UTF-8
export LANG=pt_BR.UTF-8
export LC_ALL=pt_BR.UTF-8"&gt;&gt;~/.bash_profile
locale-gen pt_BR.UTF-8
sudo dpkg-reconfigure locales
source ~/.bash_profile
```
```sh
sudo chmod +x set_locale.sh
sudo ./set_locale.sh
```

---

## Busca textual

A busca textual  confere a capacidade de identificar documentos em linguagem natural que atendam a uma consulta e, opcionalmente, classificá-los por relevância para a busca. O tipo mais comum de pesquisa é encontrar todos os documentos que contenham os termos da consulta e retorná-los em ordem de semelhança com a consulta. As noções de consulta e semelhança são muito flexíveis e dependem da aplicação específica. 

Os operadores de pesquisa textual existem nos bancos de dados há anos. O PostgreSQL possui operadores ~, ~ *, LIKE e ILIKE para tipos de dados textuais, mas eles não possuem muitas propriedades essenciais exigidas pelos modernos sistemas de informação:

- Não há suporte linguístico, mesmo para o inglês. Expressões regulares não são suficientes porque não conseguem lidar facilmente com palavras derivadas, por exemplo, satisfazer e satisfeito. 

- Eles não fornecem ordem (classificação) dos resultados da pesquisa, o que os torna ineficazes quando milhares de documentos correspondentes são encontrados.

- Eles tendem a ser lentos porque não há suporte ao índice; portanto, eles devem processar todos os documentos para cada pesquisa.

## Busca textual

A indexação de texto completo permite que os documentos sejam pré-processados e um índice salvo para posterior busca rápida. O pré-processamento inclui:

- Tokenização dos documentos;

- Conversão dos tokens em lexemas;

- Salvar documentos pré-processados e otimizados para pesquisa;

---

## Trabalhando com o PostgreSQL

Para fins de completudo, estou admitindo que você não tem familiaridade com o PostgreSQL. Isso não significa que darei explicação de cada passo, apenas que não os deixarei implícitos. Então vamos iniciar o prompt do psql:

```sql
sudo -u postgres psql
```

## TO_TSVECTOR, TO_TSQUERY e @@
As funções to_tsvector, to_tsquery e o operador @@ (match) fazem a mágica da busca textual. 

```sql
SELECT to_tsvector('portuguese','São Paulo tem o melhor SatuRday do mundo') 
@@ to_tsquery('saturday');
?column?
----------
 t
(1 row)
```
---
```sql
SELECT to_tsvector('portuguese','São Paulo tem o melhor SatuRday do mundo') 
@@ to_tsquery('saturday &amp; paulo');
?column?
----------
 t
(1 row)
```
```sql
SELECT to_tsvector('portuguese','São Paulo tem o melhor SatuRday do mundo') 
@@ to_tsquery('saturday &amp; pedro');
?column?
----------
 f
(1 row)
```
```sql
SELECT to_tsvector('portuguese','São Paulo tem o melhor SatuRday do mundo') 
@@ to_tsquery('saturday | pedro');
?column?
----------
 t
(1 row)
```
---

## Trabalhando com tabelas
No [repositório](https://github.com/jjesusfilho/FullTextSearch) consta uma base de 48 mil notícias do G1, a qual utilizaremos para fins de demonstração.

Inicialmente, vamos criar um usuário (role) e uma base de dados para receber essas notícias:

```sql
CREATE ROLE saturday WITH PASSWORD 'RshinesWithPostgres' VALID UNTIL '2019-12-01'; 
CREATE DATABASE noticias OWNER = saturday;
```
Agora nos conectamos à base, adicionamos duas extensões importantes. Uma para lidar com palavras acentuadas, outra para permitir busca fuzzy.

```sql
\c noticias
CREATE EXTENSION unaccent;
CREATE EXTENSION pg_trgm;
```
---
## Configurações necessárias

Primeiramente, iremos instalar o pacote `myspell-pt-br`:

```sh
sudo apt install myspell-pt-br
```
Feito isso, localize os os sequintes arquivos: `pt_br.aff` e `pt_br.dic`, que provavelmente estão localizados no seguinte diretório:

```sh
/usr/share/hunspell/
```
A partir deles devemos gerar os arquivos .affix e .dict respectivamente e transferi-los para o diretório `/usr/share/postgresql/versao_do_postgresql/tsearch_data/`. Este tutorial foi produzido na versão 12:

```sh
iconv -f latin1 -t UTF-8 \
/usr/share/hunspell/pt_BR.aff &gt; /usr/share/postgresql/12/tsearch_data/pt_br.affix
```
```sh
iconv -f latin1 -t UTF-8 \
/usr/share/hunspell/pt_BR.dic &gt; /usr/share/postgresql/12/tsearch_data/pt_br.dict
```
---
## Configurações necessárias

Vamos agora criar um dicionário com as palavras não acentuadas:

```sql
CREATE TEXT SEARCH CONFIGURATION pt (COPY = pg_catalog.portuguese);
ALTER TEXT SEARCH CONFIGURATION pt
ALTER MAPPING
FOR hword, hword_part, word with unaccent, portuguese_stem;
```
```sql
CREATE TEXT SEARCH DICTIONARY public.portuguese_dict (
TEMPLATE = ispell,
DictFile = pt_br,
AffFile = pt_br,
stopwords = portuguese
);
```
---
## Configurações necessárias
Agora vincular o dicinário à configuração:

```sql
ALTER TEXT SEARCH CONFIGURATION pt
   ALTER MAPPING FOR hword, hword_part, word
    WITH public.portuguese_dict, simple;

```
Não se assuste, para facilitar sua vida, eu criei uma função `psql_pt_config.R` do R que realiza todos esses passos.

---

## Indexação dos documentos

De agora em diante, passaremos a executar os queries e statemants a partir do próprio R, colocando-os dentro de funções.

A primeira coisa a fazer é conectar-se à base e adicionar a tabela. Veja que eu apenas crio a tabela, mas não insiro os documentos. Quando você tem muitos documentos, isso pode travar.

```r
conn &lt;- DBI::dbConnect(RPostgres::Postgres(),
dbname = "noticias",
host = "localhost",
user="saturday",
password = "RshinesWithPostgres")

DBI::dbCreateTable(conn,"g1",g1)
```

---
## Inserindo os documentos

Para inserir os documentos, eu prefiro usar o pacote `dbx` porque ele permite a inserção em batches. Minha experiência é que inserir centenas de milhares de documentos pode sobrecarregar sua máquina. Coloquei mil, mas 50 mil tem suportado bem.

```r
dbx::dbxInsert(con = conn, table = "g1", records = g1, batch_size = 1000)
```
## Indexando os documentos

Hora de indexar os documentos. Há dois indexadores, o GIN e o GIST, usaremos o GIN pq é mais rápido, porém mais intenso. A função a seguir cria o index estabelecendo pesos diferentes para duas colunas.

---
## Indexando os documentos
```r
psql_tokenize &lt;- function(con, tbl, config = "pt") {
  source &lt;- list(a = c("intro", "A"), j = c("corpo", "B"))
  target &lt;- "document_tokens"
  idx &lt;- paste0(tbl,"_idx")
  query &lt;- glue::glue_sql("ALTER TABLE {`tbl`} ADD COLUMN {`target`} TSVECTOR", .con = con)

  res &lt;- DBI::dbSendQuery(con, query)
  DBI::dbClearResult(res)

  query &lt;- glue::glue_sql("UPDATE {`tbl`} SET
                         {`target`} = setweight(to_tsvector({config},coalesce({`source$a[1]`},'')), {source$a[2]}) ||
                         setweight(to_tsvector({config},coalesce({`source$j[1]`}, '')), {source$j[2]})", .con = con)

  res &lt;- DBI::dbSendQuery(con, query)
  DBI::dbClearResult(res)

  query &lt;- glue::glue_sql("CREATE INDEX {`idx`} ON {`tbl`} USING GIN ({`target`})", .con = con)

  res &lt;- DBI::dbSendQuery(con, query)
  DBI::dbClearResult(res)
}
```
---
## Criando gatilho (trigger) para indexar novos documentos
A função a seguir cria um gatilho para indexar novos documentos inseridos:
---
## Criando gatilho (trigger)
```r
psql_trigger &lt;- function(con,tbl,config="pt"){

  a&lt;-"A"
  b&lt;-"B"
  intro&lt;-"new.intro"
  corpo="new.corpo"
  f_name&lt;-paste0(tbl,"_trigger()")

  q&lt;-glue::glue_sql("CREATE FUNCTION {DBI::SQL(f_name)} RETURNS trigger AS $$
begin
  new.document_tokens :=
     setweight(to_tsvector({config},coalesce({intro},'')), {a}) ||
     setweight(to_tsvector({config},coalesce({corpo},'')), {b});
  return new;
end
$$ LANGUAGE plpgsql;",.con=con)

  RPostgres::dbExecute(con,q)

  q &lt;- glue::glue_sql("
CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
    ON {`tbl`} FOR EACH ROW EXECUTE FUNCTION {DBI::SQL(f_name)}",.con=con)

  RPostgres::dbExecute(con,q)
}

```
---
## Realizando buscas:
Por fim, montamos a função para realizar as buscas
```r
psql_query &lt;-
  function (con,
            tbl,
            query = "")
  {
    
    target &lt;- "document_tokens"
    q &lt;-
      glue::glue_sql(
        "SELECT * FROM {`tbl`}  WHERE {`tbl`}.{`target`} @@ websearch_to_tsquery('pt',{query})",
        .con = con
      )
    DBI::dbGetQuery(con, q)
  }
```
---
## Inclusão no aplicativo Shiny

O [https://github.com/jjesusfilho/FullTextSearch] contém template de aplicativo para realizar as buscas.

Incluí uma função `psql_g1_dt.R` para criar um datatable htmlwidget com ajustes na aparência.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
